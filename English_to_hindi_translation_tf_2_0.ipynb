{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kbUSbXaOZ1A4",
    "outputId": "1c5900fc-403d-499c-aeed-83c27c273e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   %tensorflow_version 2.x\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EevI5OvlaAtU"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence_english(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "  \n",
    "def preprocess_sentence_hindi(w):\n",
    "    w = unicode_to_ascii(w.strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eHHd89YjeG-W",
    "outputId": "2ad38508-0921-4d16-ae2c-daeb0cfb6f97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"Hindi_English_Truncated_Corpus.csv\"\n",
    "data = pd.read_csv(PATH)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0ubkfbNqgIe0",
    "outputId": "4052fa01-7428-4e5e-cc63-bbbcefa71ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127605\n",
      "127607\n"
     ]
    }
   ],
   "source": [
    "print(data['english_sentence'].count())\n",
    "print(data['hindi_sentence'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "kwILysqlgPC9",
    "outputId": "06707e10-9f24-4830-ed78-75ece6a742cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127605\n",
      "127605\n"
     ]
    }
   ],
   "source": [
    "data = data[data['english_sentence'].map(type) == str]\n",
    "data = data[data['hindi_sentence'].map(type) == str]\n",
    "data = data[data['english_sentence'].map(len) > 0]\n",
    "data = data[data['hindi_sentence'].map(len) > 0]\n",
    "\n",
    "print(data['english_sentence'].count())\n",
    "print(data['hindi_sentence'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdU-lmbN0oFa"
   },
   "outputs": [],
   "source": [
    "data[\"token_size_en\"] = data[\"english_sentence\"].apply(lambda x: len(x.split(' ')))\n",
    "data[\"token_size_hn\"] = data[\"hindi_sentence\"].apply(lambda x: len(x.split(' ')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL0TZoax1wIb"
   },
   "outputs": [],
   "source": [
    "data = data.loc[data['token_size_hn'] < 22].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KffBysQh2uHL",
    "outputId": "ac8d2425-54d7-443c-b505-c453f007150e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90799\n"
     ]
    }
   ],
   "source": [
    "int(data['english_sentence'].count())\n",
    "print(data['hindi_sentence'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQ7lk50eAza0"
   },
   "outputs": [],
   "source": [
    "# def encode_str(string):\n",
    "#   return string.encode('UTF-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kr16Me98A7vn"
   },
   "outputs": [],
   "source": [
    "# data['english_sentence'] = data['english_sentence'].apply(encode_str)\n",
    "# data['hindi_sentence'] = data['hindi_sentence'].apply(encode_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eh4E7zgCn4eV"
   },
   "outputs": [],
   "source": [
    "data['english_sentence'] = data['english_sentence'].apply(preprocess_sentence_english)\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(preprocess_sentence_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "DzwvpL3v6wdJ",
    "outputId": "ede32e86-e678-4ed9-f872-4f5d58923cb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>token_size_en</th>\n",
       "      <th>token_size_hn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ted</td>\n",
       "      <td>&lt;start&gt; politicians do not have permission to ...</td>\n",
       "      <td>&lt;start&gt; राजनीतिजञो क पास जो कारय करना चाहिए , ...</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ted</td>\n",
       "      <td>&lt;start&gt; i d like to tell you about one such ch...</td>\n",
       "      <td>&lt;start&gt; मई आपको ऐस ही एक बचच क बार म बताना चाह...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>indic2012</td>\n",
       "      <td>&lt;start&gt; this percentage is even greater than t...</td>\n",
       "      <td>&lt;start&gt; यह परतिशत भारत म हिनदओ परतिशत स अधिक ह...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ted</td>\n",
       "      <td>&lt;start&gt; what we really mean is that they re ba...</td>\n",
       "      <td>&lt;start&gt; हम य नही कहना चाहत कि वो धयान नही द पा...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>indic2012</td>\n",
       "      <td>&lt;start&gt; . the ending portion of these vedas is...</td>\n",
       "      <td>&lt;start&gt; इनही वदो का अतिम भाग उपनिषद कहलाता ह। ...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  <start> politicians do not have permission to ...   \n",
       "1        ted  <start> i d like to tell you about one such ch...   \n",
       "2  indic2012  <start> this percentage is even greater than t...   \n",
       "3        ted  <start> what we really mean is that they re ba...   \n",
       "4  indic2012  <start> . the ending portion of these vedas is...   \n",
       "\n",
       "                                      hindi_sentence  token_size_en  \\\n",
       "0  <start> राजनीतिजञो क पास जो कारय करना चाहिए , ...             12   \n",
       "1  <start> मई आपको ऐस ही एक बचच क बार म बताना चाह...              9   \n",
       "2  <start> यह परतिशत भारत म हिनदओ परतिशत स अधिक ह...             10   \n",
       "3  <start> हम य नही कहना चाहत कि वो धयान नही द पा...             12   \n",
       "4  <start> इनही वदो का अतिम भाग उपनिषद कहलाता ह। ...              9   \n",
       "\n",
       "   token_size_hn  \n",
       "0             14  \n",
       "1             11  \n",
       "2              9  \n",
       "3             11  \n",
       "4              8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlVsUEz66ziv"
   },
   "outputs": [],
   "source": [
    "en = data['english_sentence'].values.tolist()\n",
    "hn = data['hindi_sentence'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TR4CSGU55nvZ",
    "outputId": "550a899e-79b0-4d96-8137-3a316d66a10d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90799, 90799)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en),len(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3iBhaa8y7tpz",
    "outputId": "4e02b506-8b24-4353-ae53-bb37b8bea287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start> they ve just won four government contracts to build off their ambulances , <end>',\n",
       " '<start> हाल ही म उनह सरकारी ठका मिला ह करीब सौ नई अमबलनस बनान का , <end>')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en[-1],hn[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuNkT-v57wlM"
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnQIvai97_11"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5q-fxTW8Aru"
   },
   "outputs": [],
   "source": [
    "def load_dataset(num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = data['hindi_sentence'].values.tolist()[:num_examples],data['english_sentence'].values.tolist()[:num_examples]\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wy1hWeH8vEG"
   },
   "outputs": [],
   "source": [
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(35000)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "ptQTrp_p86il",
    "outputId": "23f26fcb-dea1-440b-d295-397760915f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 31\n",
      "35000 [[   1 7745    4  109   29  197   92  106    7   52   36   16 1806   19\n",
      "     3    5    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   1 1404  112  176   23   14  217    4   51    6 1129 2600    7    2\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(max_length_inp,max_length_targ)\n",
    "print(len(input_tensor),target_tensor[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d2kpbMRv89en",
    "outputId": "0dcbab70-d385-4b5a-c965-86ceeacee374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 28000 7000 7000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMSKb1I_9MsE"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "colab_type": "code",
    "id": "4o853ceL9Vtv",
    "outputId": "efebf004-abbd-4786-da1d-ec371e252e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "9 ----> in\n",
      "25 ----> he\n",
      "132 ----> got\n",
      "4 ----> the\n",
      "6555 ----> filmfare\n",
      "872 ----> award\n",
      "20 ----> for\n",
      "4 ----> the\n",
      "266 ----> best\n",
      "2709 ----> actor\n",
      "20 ----> for\n",
      "4 ----> the\n",
      "462 ----> role\n",
      "6 ----> of\n",
      "3741 ----> amar\n",
      "184 ----> akbar\n",
      "3742 ----> anthony\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6727 ----> १९७७\n",
      "6 ----> म\n",
      "1096 ----> इनहोन\n",
      "2710 ----> अमर\n",
      "219 ----> अकबर\n",
      "8263 ----> एनथनी\n",
      "6 ----> म\n",
      "37 ----> अपन\n",
      "1602 ----> परदरशन\n",
      "4 ----> क\n",
      "24 ----> लिए\n",
      "2167 ----> सरवशरषठ\n",
      "3395 ----> अभिनता\n",
      "11 ----> का\n",
      "4972 ----> फिलमफयर\n",
      "545 ----> परसकार\n",
      "6728 ----> जीता।\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M17-MMtK9V-x"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xUuPc4ty9qcZ",
    "outputId": "5f8bd5b1-75b0-4b65-b5c3-fb15f857cb0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 48]), TensorShape([64, 31]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oshfTta9tvZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ub-Oi_EP9x1X",
    "outputId": "74b485d1-1242-4633-9747-38b5ecfb491c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 48, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvzOK_RH90cT"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Op1F1rpf94NH",
    "outputId": "e9f9823c-5435-4aeb-a8d7-a359757c8629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ru9lnAJ99v1"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rRb2wJKH9_c1",
    "outputId": "f7327bfb-e15a-4f08-e5f7-c3561922d4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 27722)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIl0d2w0-BTy"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjaZAbAp-DwU"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZKITmh6-FwB"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ma0crou8-HvX",
    "outputId": "3b8d03fd-6923-4db5-c5a7-9b22ac067c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.6609\n",
      "Epoch 1 Batch 100 Loss 2.5505\n",
      "Epoch 1 Batch 200 Loss 2.5381\n",
      "Epoch 1 Batch 300 Loss 2.4214\n",
      "Epoch 1 Batch 400 Loss 2.2936\n",
      "Epoch 1 Loss 2.5496\n",
      "Time taken for 1 epoch 334.2392861843109 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.1911\n",
      "Epoch 2 Batch 100 Loss 2.2041\n",
      "Epoch 2 Batch 200 Loss 2.0321\n",
      "Epoch 2 Batch 300 Loss 2.5544\n",
      "Epoch 2 Batch 400 Loss 2.0181\n",
      "Epoch 2 Loss 2.2074\n",
      "Time taken for 1 epoch 315.29234886169434 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.8320\n",
      "Epoch 3 Batch 100 Loss 2.2029\n",
      "Epoch 3 Batch 200 Loss 2.0372\n",
      "Epoch 3 Batch 300 Loss 2.2875\n",
      "Epoch 3 Batch 400 Loss 2.1488\n",
      "Epoch 3 Loss 1.9763\n",
      "Time taken for 1 epoch 305.95008659362793 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.7214\n",
      "Epoch 4 Batch 100 Loss 1.9824\n",
      "Epoch 4 Batch 200 Loss 1.9184\n",
      "Epoch 4 Batch 300 Loss 1.6821\n",
      "Epoch 4 Batch 400 Loss 1.9371\n",
      "Epoch 4 Loss 1.7396\n",
      "Time taken for 1 epoch 316.46778750419617 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.5124\n",
      "Epoch 5 Batch 100 Loss 1.6091\n",
      "Epoch 5 Batch 200 Loss 1.4146\n",
      "Epoch 5 Batch 300 Loss 1.4384\n",
      "Epoch 5 Batch 400 Loss 1.6765\n",
      "Epoch 5 Loss 1.4913\n",
      "Time taken for 1 epoch 306.12281107902527 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1563\n",
      "Epoch 6 Batch 100 Loss 1.2136\n",
      "Epoch 6 Batch 200 Loss 1.2320\n",
      "Epoch 6 Batch 300 Loss 1.0608\n",
      "Epoch 6 Batch 400 Loss 1.3055\n",
      "Epoch 6 Loss 1.2444\n",
      "Time taken for 1 epoch 316.8793351650238 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.9924\n",
      "Epoch 7 Batch 100 Loss 0.9183\n",
      "Epoch 7 Batch 200 Loss 0.9550\n",
      "Epoch 7 Batch 300 Loss 1.0976\n",
      "Epoch 7 Batch 400 Loss 0.9795\n",
      "Epoch 7 Loss 1.0168\n",
      "Time taken for 1 epoch 306.25835061073303 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.8308\n",
      "Epoch 8 Batch 100 Loss 0.7200\n",
      "Epoch 8 Batch 200 Loss 0.7778\n",
      "Epoch 8 Batch 300 Loss 0.8606\n",
      "Epoch 8 Batch 400 Loss 0.9041\n",
      "Epoch 8 Loss 0.8243\n",
      "Time taken for 1 epoch 314.65996384620667 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.7317\n",
      "Epoch 9 Batch 100 Loss 0.6280\n",
      "Epoch 9 Batch 200 Loss 0.6292\n",
      "Epoch 9 Batch 300 Loss 0.7239\n",
      "Epoch 9 Batch 400 Loss 0.7142\n",
      "Epoch 9 Loss 0.6682\n",
      "Time taken for 1 epoch 305.6628201007843 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.4429\n",
      "Epoch 10 Batch 100 Loss 0.4424\n",
      "Epoch 10 Batch 200 Loss 0.4537\n",
      "Epoch 10 Batch 300 Loss 0.4818\n",
      "Epoch 10 Batch 400 Loss 0.6010\n",
      "Epoch 10 Loss 0.5367\n",
      "Time taken for 1 epoch 317.10713601112366 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.3620\n",
      "Epoch 11 Batch 100 Loss 0.4497\n",
      "Epoch 11 Batch 200 Loss 0.4179\n",
      "Epoch 11 Batch 300 Loss 0.4911\n",
      "Epoch 11 Batch 400 Loss 0.5214\n",
      "Epoch 11 Loss 0.4267\n",
      "Time taken for 1 epoch 303.7030098438263 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.3098\n",
      "Epoch 12 Batch 100 Loss 0.3482\n",
      "Epoch 12 Batch 200 Loss 0.3710\n",
      "Epoch 12 Batch 300 Loss 0.3968\n",
      "Epoch 12 Batch 400 Loss 0.3645\n",
      "Epoch 12 Loss 0.3346\n",
      "Time taken for 1 epoch 316.96915674209595 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2780\n",
      "Epoch 13 Batch 100 Loss 0.2533\n",
      "Epoch 13 Batch 200 Loss 0.2892\n",
      "Epoch 13 Batch 300 Loss 0.2251\n",
      "Epoch 13 Batch 400 Loss 0.2403\n",
      "Epoch 13 Loss 0.2587\n",
      "Time taken for 1 epoch 306.388879776001 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.2270\n",
      "Epoch 14 Batch 100 Loss 0.1805\n",
      "Epoch 14 Batch 200 Loss 0.2139\n",
      "Epoch 14 Batch 300 Loss 0.1866\n",
      "Epoch 14 Batch 400 Loss 0.2132\n",
      "Epoch 14 Loss 0.1974\n",
      "Time taken for 1 epoch 316.9617168903351 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1429\n",
      "Epoch 15 Batch 100 Loss 0.1590\n",
      "Epoch 15 Batch 200 Loss 0.1542\n",
      "Epoch 15 Batch 300 Loss 0.1304\n",
      "Epoch 15 Batch 400 Loss 0.1620\n",
      "Epoch 15 Loss 0.1514\n",
      "Time taken for 1 epoch 306.84876918792725 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1037\n",
      "Epoch 16 Batch 100 Loss 0.1349\n",
      "Epoch 16 Batch 200 Loss 0.1470\n",
      "Epoch 16 Batch 300 Loss 0.1193\n",
      "Epoch 16 Batch 400 Loss 0.1586\n",
      "Epoch 16 Loss 0.1280\n",
      "Time taken for 1 epoch 317.23932123184204 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1055\n",
      "Epoch 17 Batch 100 Loss 0.0838\n",
      "Epoch 17 Batch 200 Loss 0.0753\n",
      "Epoch 17 Batch 300 Loss 0.0972\n",
      "Epoch 17 Batch 400 Loss 0.0956\n",
      "Epoch 17 Loss 0.0892\n",
      "Time taken for 1 epoch 306.96110343933105 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0556\n",
      "Epoch 18 Batch 100 Loss 0.0722\n",
      "Epoch 18 Batch 200 Loss 0.0600\n",
      "Epoch 18 Batch 300 Loss 0.0552\n",
      "Epoch 18 Batch 400 Loss 0.0763\n",
      "Epoch 18 Loss 0.0670\n",
      "Time taken for 1 epoch 316.2596652507782 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0575\n",
      "Epoch 19 Batch 100 Loss 0.0467\n",
      "Epoch 19 Batch 200 Loss 0.0558\n",
      "Epoch 19 Batch 300 Loss 0.0685\n",
      "Epoch 19 Batch 400 Loss 0.0544\n",
      "Epoch 19 Loss 0.0550\n",
      "Time taken for 1 epoch 304.8092231750488 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0450\n",
      "Epoch 20 Batch 100 Loss 0.0610\n",
      "Epoch 20 Batch 200 Loss 0.0500\n",
      "Epoch 20 Batch 300 Loss 0.0513\n",
      "Epoch 20 Batch 400 Loss 0.0705\n",
      "Epoch 20 Loss 0.0507\n",
      "Time taken for 1 epoch 317.99033403396606 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrveI0pa-KqQ"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence_english(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTSIYJci9IZx"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBuJNC0V9KgW"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wEuVv59X9MOx",
    "outputId": "861cef3c-4c13-4531-e18f-36e101446129"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19aba8c6908>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "weQqfKRi9OrH",
    "outputId": "a927c038-774e-4edc-d130-7488df23b292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> home <end>\n",
      "Predicted translation: घर <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "Z43sFWgO_l5S",
    "outputId": "19720f61-6310-42de-a108-38c141934b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> work <end>\n",
      "Predicted translation: कारय <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(' work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "English_to_hindi_translation_tf-2.0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
